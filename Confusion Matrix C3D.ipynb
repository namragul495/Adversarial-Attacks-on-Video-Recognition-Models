{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5133d9ec-1b81-4589-b19f-f26effc165c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "orignal =[] #Blank array. But later on add normal and abnormal to it. original has all the labels we got during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5dc95e3-1d01-4802-aae9-67cd1d5c3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all test videos\n",
    "test=[] #It contains all labels (0 and 1). Length is 85 \n",
    "test_list2=[]\n",
    "f= 'sample_images_RA'\n",
    "Test_videos =[]  #This array contains path of all videos.Length is 85\n",
    "test_list = open('Labels/test.txt','r') # path and labels info \n",
    "for line in test_list:\n",
    "    name = line.split(\" \")[0]  \n",
    "    test_list2.append(line)\n",
    "    x=line.split(\" \")[-1]\n",
    "    test.append(x[0])\n",
    "    Test_videos.append(f+\"/\"+name) #Full path of all videos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d979bd6-a028-446f-8064-38311c43203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test: \n",
    "    if i=='0':\n",
    "        orignal.append('normal')\n",
    "    else:\n",
    "        orignal.append('abnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a91d574e-85c1-4c8c-a278-8f62d415aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load pre-trained model, trained on 5 classes \n",
    "#model = tf.keras.models.load_model('Trained models/model_c3d.h5',compile=False)\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "#To load pre-trained weeights,\n",
    "model = tf.keras.models.load_model('Trained Models/weights_model_C3D.hdf5',compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8041b922-4f68-4679-b123-558095e05419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Five class labels\n",
    "labels1 = {0: 'fighting', 1: 'vandalism',2: '0normal',3: 'shooting',4: 'hockeyfight'}\n",
    "prediction = [] #Labels you get after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "122c2f74-d959-4813-99a8-25ebaf83ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for Confusion Matrix\n",
    "for video in Test_videos:\n",
    "    vid = [] #reads frame of videos\n",
    "    #nor=0  #no value of nor. initialize nor with 0\n",
    "    abnor=0   #no value of abnor. initialize abnor 0\n",
    "    path=video\n",
    "    images = os.listdir(path) #Images name actually store name of all frames\n",
    "    for img in images: #read the length and width of all images.\n",
    "        img_path=path +\"/\"+img #path +img name print. path of 1 frame\n",
    "        img2 = cv2.imread(img_path) #img2 has a 2D array of integer form containing length and width of videos\n",
    "        img2= cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "        vid.append(cv2.resize(img2, (112, 112))) \n",
    "    vid = np.array(vid, dtype=np.float32) #model accepts float32 type of array from training code. (no of frames, length, width)\n",
    "    for i in range(0,len(vid),32): #len is actually no of frames.\n",
    "        X = vid[i:i+32].transpose((2,1,0,3)) #model takes 32 frames.\n",
    "        output = model.predict_on_batch(np.array([X]))\n",
    "        if abnor==3:\n",
    "            break\n",
    "        if(len(output)>0): #code doesnot break\n",
    "            str1=labels1[np.argmax(output)] #on which location of labels is the max probablity of o/p\n",
    "            if str1=='vandalism' or str1 == 'fighting' or str1=='shooting' or str1=='hockeyfight':\n",
    "                abnor=abnor+1\n",
    "            else:\n",
    "                abnor=0\n",
    "    \n",
    "    vid=[]\n",
    "    if abnor==3:\n",
    "         prediction.append('abnormal')\n",
    "    else:\n",
    "        prediction.append('normal')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76f7d2c5-6ba4-4145-b2ff-2594ef982e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction) #prediction array has labels we got during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90bc2501-b25c-49a5-a788-1be31177c0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(orignal, prediction)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9686280-7e02-440d-b05d-076891810bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
