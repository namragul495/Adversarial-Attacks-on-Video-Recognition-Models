{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5133d9ec-1b81-4589-b19f-f26effc165c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "orignal =[] #Blank array. But later on add normal and abnormal to it. original has all the labels we got during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5dc95e3-1d01-4802-aae9-67cd1d5c3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all test videos\n",
    "test=[] #It contains all labels (0 and 1). Length is 85 \n",
    "test_list2=[]\n",
    "f= 'sample_images_RA'\n",
    "Test_videos =[]  #This array contains path of all videos.Length is 85\n",
    "test_list = open('Labels/test.txt','r') # path and labels info \n",
    "for line in test_list:\n",
    "    name = line.split(\" \")[0]  \n",
    "    test_list2.append(line)\n",
    "    x=line.split(\" \")[-1]\n",
    "    test.append(x[0])\n",
    "    Test_videos.append(f+\"/\"+name) #Full path of all videos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d979bd6-a028-446f-8064-38311c43203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test: \n",
    "    if i=='0':\n",
    "        orignal.append('normal')\n",
    "    else:\n",
    "        orignal.append('abnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a91d574e-85c1-4c8c-a278-8f62d415aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load pre-trained model, trained on 5 classes \n",
    "#model = tf.keras.models.load_model('Trained models/model_c3d.h5',compile=False)\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "#To load pre-trained weeights,\n",
    "model = tf.keras.models.load_model('Trained Models/weights_model_C3D.hdf5',compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8041b922-4f68-4679-b123-558095e05419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Five class labels\n",
    "labels1 = {0: 'fighting', 1: 'vandalism',2: '0normal',3: 'shooting',4: 'hockeyfight'}\n",
    "prediction = [] #Labels you get after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "302eb5ec-128c-4409-9b83-5669f049319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image, mean=2, sigma=4.25):\n",
    "    gaussian_noise = np.random.normal(mean, sigma, image.shape).astype('uint8')\n",
    "    noisy_image = cv2.add(image, gaussian_noise)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e91f52e7-8dc4-4697-9433-de52dca2a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(image, kernel_size=5):\n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "122c2f74-d959-4813-99a8-25ebaf83ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for Confusion Matrix\n",
    "for video in Test_videos:\n",
    "    vid = [] #reads frame of videos\n",
    "    #nor=0  #no value of nor. initialize nor with 0\n",
    "    abnor=0   #no value of abnor. initialize abnor 0\n",
    "    path=video\n",
    "    images = os.listdir(path) #Images name actually store name of all frames\n",
    "    for img in images: #read the length and width of all images.\n",
    "        img_path=path +\"/\"+img #path +img name print. path of 1 frame\n",
    "        img2 = cv2.imread(img_path) #img2 has a 2D array of integer form containing length and width of videos\n",
    "        img2 = add_gaussian_noise(img2, mean=2, sigma=4.25)\n",
    "        img2 = gaussian_blur(img2)\n",
    "        img2= cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "        vid.append(cv2.resize(img2, (112, 112))) \n",
    "    vid = np.array(vid, dtype=np.float32) #model accepts float32 type of array from training code. (no of frames, length, width)\n",
    "    for i in range(0,len(vid),32): #len is actually no of frames.\n",
    "        X = vid[i:i+32].transpose((2,1,0,3)) #model takes 32 frames.\n",
    "        output = model.predict_on_batch(np.array([X]))\n",
    "        if abnor==3:\n",
    "            break\n",
    "        if(len(output)>0): #code doesnot break\n",
    "            str1=labels1[np.argmax(output)] #on which location of labels is the max probablity of o/p\n",
    "            if str1=='vandalism' or str1 == 'fighting' or str1=='shooting' or str1=='hockeyfight':\n",
    "                abnor=abnor+1\n",
    "            else:\n",
    "                abnor=0\n",
    "    \n",
    "    vid=[]\n",
    "    if abnor==3:\n",
    "         prediction.append('abnormal')\n",
    "    else:\n",
    "        prediction.append('normal')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76f7d2c5-6ba4-4145-b2ff-2594ef982e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction) #prediction array has labels we got during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90bc2501-b25c-49a5-a788-1be31177c0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(orignal, prediction)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9686280-7e02-440d-b05d-076891810bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
