{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a978abde-6587-430e-a0fa-e9340f1d5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "orignal =[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3e5fed3-95a2-484d-bb6a-e27adebcc39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all test videos\n",
    "test=[]\n",
    "f= 'sample_images_RA'\n",
    "Test_videos =[]\n",
    "test_list = open('Labels/test.txt','r')\n",
    "for line in test_list:\n",
    "    name = line.split(\" \")[0]\n",
    "    x=line.split(\" \")[-1]\n",
    "    test.append(x[0])\n",
    "    Test_videos.append(f+\"/\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42d7a932-2fd6-4201-8b0d-10a1f8e7c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test:\n",
    "    if i=='0':\n",
    "        orignal.append('normal')\n",
    "    else:\n",
    "        orignal.append('abnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45965bae-29b0-4176-bfd4-af9785dbb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load pre-trained model, trained on 5 classes \n",
    "#model = tf.keras.models.load_model('Trained Models/model_P3D.h5',compile=False)\n",
    "\n",
    "\n",
    "#To load pre-trained weights,\n",
    "model = tf.keras.models.load_model('Trained Models/weights_model_P3D.hdf5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b20509b4-f21a-4c7d-a5c6-96cdadb1fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two classes labels\n",
    "labels0 ={0:'normal', 1:'abnormal'}\n",
    "prediction = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cac703-2ed7-4684-88ee-399264910f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(frames, frame_rate=5):\n",
    "    \"\"\"\n",
    "    Play a sequence of frames as a video.\n",
    "\n",
    "    Parameters:\n",
    "    - frames: List of frames (numpy arrays representing images).\n",
    "    - frame_rate: Frames per second (default is 25).\n",
    "    \"\"\"\n",
    "    if not frames:\n",
    "        print(\"No frames to play.\")\n",
    "        return\n",
    "\n",
    "    # Get the height and width from the first frame\n",
    "    height, width, _ = frames[0].shape\n",
    "    size = (width, height)\n",
    "\n",
    "    # Create a VideoWriter object to save the video\n",
    "    video_writer = cv2.VideoWriter('output_video.avi', cv2.VideoWriter_fourcc(*'DIVX'), frame_rate, size)\n",
    "\n",
    "    # Display each frame and write it to the video file\n",
    "    for frame in frames:\n",
    "        cv2.imshow('Video Player', frame)\n",
    "        video_writer.write(frame)\n",
    "\n",
    "        # Break the loop if the 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the VideoWriter and close the OpenCV window\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84493528-9c8d-4815-8ff0-bdefe1b7772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in Test_videos:\n",
    "    vid = []  # reads frames of videos\n",
    "    abnor = 0  # initialize abnormal count with 0\n",
    "    path = video\n",
    "    images = os.listdir(path)\n",
    "\n",
    "    # Define frame drop rate\n",
    "    frame_drop_rate = 3  # For example, drop every 2nd frame\n",
    "\n",
    "    for idx, img in enumerate(images):\n",
    "        if idx % frame_drop_rate == 0:  # Skip frames based on frame_drop_rate\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(path, img)\n",
    "        img2 = cv2.imread(img_path)\n",
    "        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "        vid.append(cv2.resize(img2, (112, 112)))\n",
    "\n",
    "        if len(vid) == 32:\n",
    "            X = np.array(vid, dtype=np.float32).transpose((2, 1, 0, 3))\n",
    "            output = model.predict_on_batch(np.array([X]))\n",
    "\n",
    "            if abnor == 3:\n",
    "                break\n",
    "\n",
    "            if len(output) > 0:\n",
    "                str1 = labels0[np.argmax(output)]\n",
    "                if str1 in ['vandalism', 'fighting', 'shooting', 'hockeyfight']:\n",
    "                    abnor += 1\n",
    "                else:\n",
    "                    abnor = 0\n",
    "\n",
    "            vid = []\n",
    "\n",
    "    if abnor == 3:\n",
    "        prediction.append('abnormal')\n",
    "    else:\n",
    "        prediction.append('normal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdcd568-1fc2-44fb-b91d-9a5e558fe4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b914b-737c-4620-9198-07ea1f23e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c4ca0-8729-444a-aa83-bc3ba6e39097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_images_RA/0Normal/1Fighting037_x264 normal normal\n",
      "sample_images_RA/0Normal/1Fighting038_x264 normal normal\n",
      "sample_images_RA/0Normal/1Fighting039_x264 normal normal\n",
      "sample_images_RA/0Normal/1Shooting002_x264 normal normal\n",
      "sample_images_RA/0Normal/1Shooting003_x264 normal normal\n",
      "sample_images_RA/0Normal/1Shooting004_x264 normal normal\n",
      "sample_images_RA/0Normal/1Vandalism019_x264 normal normal\n",
      "sample_images_RA/0Normal/1Vandalism020_x264 normal normal\n",
      "sample_images_RA/fighting/2Fighting015_x264 abnormal normal\n",
      "sample_images_RA/fighting/2Fighting016_x264 abnormal normal\n",
      "sample_images_RA/shooting/2Shooting038_x264 abnormal normal\n",
      "sample_images_RA/shooting/2Shooting053_x264 abnormal normal\n",
      "sample_images_RA/shooting/2Shooting054_x264 abnormal normal\n",
      "sample_images_RA/vandalism/2Vandalism036_x264 abnormal normal\n",
      "sample_images_RA/vandalism/2Vandalism037_x264 abnormal normal\n",
      "sample_images_RA/vandalism/2Vandalism038_x264 abnormal normal\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for i in Test_videos:\n",
    "    print(i, orignal[j], prediction[j])\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0f703e-4936-4ef1-a5fe-375a1b0f873c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAGdCAYAAADJ366iAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAPPklEQVR4nO3bf2zV9b3H8fdphXbG6LB1gE5nHBEcIjhAfiTLgsKQbSo6dJq5ADH+GJNldBrFi1bNIjrIdFwgbm4oc+5q2AZzXNE5rs7MFHAoYMD9oZLMZIAUGEaCRdtz/7iT24qiteX9dZzHI+EPPt/Tk9cfTZ58v+dQKpfL5QCABFVFDwCgcogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANIcUfSAd731TtEL4NDqNfzaoifAIbP3hfkf6XXudABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiU4Ee/vVDMWHc2TH8zEHxrUsvjhc3bCh6EnRZVVUpbpn2tXhp+a2xs+nHsfHRxrjxynOLnsV7iE6FeXzFYzH3R7Pj6mnfjYeXLI3+/QfEd66+Inbs2FH0NOiSH0wZF1dO+lLMuHNJDLnohzFr3u+jYfLYmHbZl4ueRjuiU2EeXHx/XDTpkph44Tfi8/36xazG26K2tjaW/e63RU+DLhk5+JRY/ucN8fhfNsbft+yMpX9aFytX/S2GDfxc0dNoR3QqyNv79sVLmzbGyFGj959VVVXFyJGjY8P6FwpcBl23av2rMeas/tHvpM9ERMSgU0+IUUNOiT8+u6ngZbR3RGd/oLm5ORYtWhRNTU2xdevWiIjo06dPjB49OqZMmRLHHXdct4+ke+z6565obW2Nurq6Dud1dXWxefOrBa2C7jH3/ifj6KNqY/3SWdHaWo7q6lI0LlgeD6/4a9HTaKdT0Xnuuedi/PjxceSRR8bYsWPj1FNPjYiIbdu2xbx58+LOO++MJ554IoYNG3bQ92lpaYmWlpYOZ+XqmqipqenkfID/M+krX4xLJwyPKTctjk2vbIkz+p8Qc66bFFu2746H/rC66Hn8S6eiM3369Lj44ovj3nvvjVKp1OFauVyOa665JqZPnx5NTU0HfZ/Zs2fHbbfd1uHsP25ujFm33NqZOXRSr0/3iurq6gO+NLBjx46or68vaBV0jzu+PzHm3v9kLHlibUREbHz5H3FS32Pj+qnjROcTpFOf6axfvz5mzJhxQHAiIkqlUsyYMSPWrVv3oe8zc+bM2L17d4c/198wszNT+Bh69OwZp31hYKxe9f//KGhra4vVq5vijMFnFrgMuu5TtT2jrdzW4ay1rRxVVT66/iTp1J1Onz59Ys2aNTFgwID3vb5mzZro3bv3h75PTc2Bj9LeeqczS/i4vj15atx80w0xcODpcfqgM+JXDy6OvXv3xsQLLyp6GnTJY8+8GDdcMT5e27IrNr2yJYYM+Gx87/Ix8ctlq4qeRjudis51110XV111VaxduzbOOeec/YHZtm1brFy5Mu67776YO3fuIRlK9zh3wldj186dsXD+vGhu3h79B5wWC3/686jzeI1/cw13LYnGaV+Pn9z0zTiu11GxZfvu+MVvno07frai6Gm0UyqXy+XO/MAjjzwSd999d6xduzZaW1sjIqK6ujqGDh0aDQ0Ncckll3ysIe50ONz1Gn5t0RPgkNn7wvyP9LpOR+ddb7/9djQ3N0dERH19ffTo0ePjvM1+osPhTnQ4nH3U6HT6/+m8q0ePHtG3b9+P++MAVCBf6wAgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkEZ0K9PCvH4oJ486O4WcOim9denG8uGFD0ZOgy6qqSnHLtK/FS8tvjZ1NP46NjzbGjVeeW/Qs3kN0KszjKx6LuT+aHVdP+248vGRp9O8/IL5z9RWxY8eOoqdBl/xgyri4ctKXYsadS2LIRT+MWfN+Hw2Tx8a0y75c9DTaEZ0K8+Di++OiSZfExAu/EZ/v1y9mNd4WtbW1sex3vy16GnTJyMGnxPI/b4jH/7Ix/r5lZyz907pYuepvMWzg54qeRjuiU0He3rcvXtq0MUaOGr3/rKqqKkaOHB0b1r9Q4DLoulXrX40xZ/WPfid9JiIiBp16Qowackr88dlNBS+jvSOKHkCeXf/cFa2trVFXV9fhvK6uLjZvfrWgVdA95t7/ZBx9VG2sXzorWlvLUV1disYFy+PhFX8tehrtdHt0XnvttWhsbIxFixZ94GtaWlqipaWlw1m5uiZqamq6ew5QISZ95Ytx6YThMeWmxbHplS1xRv8TYs51k2LL9t3x0B9WFz2Pf+n2x2s7d+6MxYsXH/Q1s2fPjmOOOabDnzl3ze7uKbxHr0/3iurq6gO+NLBjx46or68vaBV0jzu+PzHm3v9kLHlibWx8+R/xX//9XPznQ/8T108dV/Q02un0nc6jjz560Ouvvvrhj2lmzpwZDQ0NHc7K1e5yDrUePXvGaV8YGKtXNcXZ54yNiIi2trZYvbopLr3s8oLXQdd8qrZntJXbOpy1tpWjqspH158knY7OxIkTo1QqRblc/sDXlEqlg75HTc2Bj9LeeqezS/g4vj15atx80w0xcODpcfqgM+JXDy6OvXv3xsQLLyp6GnTJY8+8GDdcMT5e27IrNr2yJYYM+Gx87/Ix8ctlq4qeRjudjk7fvn1j4cKFccEFF7zv9XXr1sXQoUO7PIxD49wJX41dO3fGwvnzorl5e/QfcFos/OnPo87jNf7NNdy1JBqnfT1+ctM347heR8WW7bvjF795Nu742Yqip9FOqXywW5b3cf7558eQIUPi9ttvf9/r69evjzPPPDPa2tre9/oHcafD4a7X8GuLngCHzN4X5n+k13X6Tuf666+PPXv2fOD1fv36xVNPPdXZtwWgAnT6TudQcafD4c6dDoezj3qn42sdAKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASCM6AKQRHQDSiA4AaUQHgDSiA0Aa0QEgjegAkEZ0AEgjOgCkER0A0ogOAGlEB4A0ogNAmlK5XC4XPYJcLS0tMXv27Jg5c2bU1NQUPQe6nd/xTy7RqUBvvPFGHHPMMbF79+44+uiji54D3c7v+CeXx2sApBEdANKIDgBpRKcC1dTURGNjow9YOWz5Hf/k8kUCANK40wEgjegAkEZ0AEgjOgCkEZ0KtGDBgjj55JOjtrY2RowYEWvWrCl6EnSLZ555Js4777w4/vjjo1QqxbJly4qexHuIToV55JFHoqGhIRobG+P555+PwYMHx/jx4+P1118vehp02Z49e2Lw4MGxYMGCoqfwAXxlusKMGDEihg8fHvPnz4+IiLa2tjjxxBNj+vTpceONNxa8DrpPqVSKpUuXxsSJE4ueQjvudCrIvn37Yu3atTF27Nj9Z1VVVTF27NhoamoqcBlQKUSngjQ3N0dra2v07t27w3nv3r1j69atBa0CKonoAJBGdCpIfX19VFdXx7Zt2zqcb9u2Lfr06VPQKqCSiE4F6dmzZwwdOjRWrly5/6ytrS1WrlwZo0aNKnAZUCmOKHoAuRoaGmLy5MkxbNiwOOuss+Kee+6JPXv2xNSpU4ueBl325ptvxssvv7z/75s3b45169bFscceGyeddFKBy3iXr0xXoPnz58ecOXNi69atMWTIkJg3b16MGDGi6FnQZU8//XSMGTPmgPPJkyfHAw88kD+IA4gOAGl8pgNAGtEBII3oAJBGdABIIzoApBEdANKIDgBpRAeANKIDQBrRASCN6ACQRnQASPO/SrTlLV6PKVcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(orignal, prediction)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dad7dd-a8a4-4826-9c71-d20627c24fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd06bf5-2a4f-4c5a-a910-bee48b508564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
