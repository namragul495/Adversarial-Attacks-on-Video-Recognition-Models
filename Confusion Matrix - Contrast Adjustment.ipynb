{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5133d9ec-1b81-4589-b19f-f26effc165c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "orignal =[] #Blank array. But later on add normal and abnormal to it. original has all the labels we got during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5dc95e3-1d01-4802-aae9-67cd1d5c3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all test videos\n",
    "test=[] #It contains all labels (0 and 1). Length is 85 \n",
    "test_list2=[]\n",
    "f= 'sample_images_RA'\n",
    "Test_videos =[]  #This array contains path of all videos.Length is 85\n",
    "test_list = open('Labels/test.txt','r') # path and labels info \n",
    "for line in test_list:\n",
    "    name = line.split(\" \")[0]  \n",
    "    test_list2.append(line)\n",
    "    x=line.split(\" \")[-1]\n",
    "    test.append(x[0])\n",
    "    Test_videos.append(f+\"/\"+name) #Full path of all videos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d979bd6-a028-446f-8064-38311c43203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test: \n",
    "    if i=='0':\n",
    "        orignal.append('normal')\n",
    "    else:\n",
    "        orignal.append('abnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91d574e-85c1-4c8c-a278-8f62d415aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load pre-trained model, trained on 5 classes \n",
    "#model = tf.keras.models.load_model('Trained models/model_c3d.h5',compile=False)\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "#To load pre-trained weeights,\n",
    "model = tf.keras.models.load_model('Trained Models/weights_model_C3D.hdf5',compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8041b922-4f68-4679-b123-558095e05419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Five class labels\n",
    "labels1 = {0: 'fighting', 1: 'vandalism',2: '0normal',3: 'shooting',4: 'hockeyfight'}\n",
    "prediction = [] #Labels you get after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302eb5ec-128c-4409-9b83-5669f049319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_contrast(frame, alpha=1.0, beta=0.0):\n",
    "    contrasted_frame = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)\n",
    "    return contrasted_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122c2f74-d959-4813-99a8-25ebaf83ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for Confusion Matrix\n",
    "for video in Test_videos:\n",
    "    vid = [] #reads frame of videos\n",
    "    #nor=0  #no value of nor. initialize nor with 0\n",
    "    abnor=0   #no value of abnor. initialize abnor 0\n",
    "    path=video\n",
    "    images = os.listdir(path) #Images name actually store name of all frames\n",
    "    for img in images: #read the length and width of all images.\n",
    "        img_path=path +\"/\"+img #path +img name print. path of 1 frame\n",
    "        img2 = cv2.imread(img_path) #img2 has a 2D array of integer form containing length and width of videos\n",
    "        img2 = adjust_contrast(img2, alpha=1.0, beta=0.0)\n",
    "        img2= cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "        vid.append(cv2.resize(img2, (112, 112))) \n",
    "    vid = np.array(vid, dtype=np.float32) #model accepts float32 type of array from training code. (no of frames, length, width)\n",
    "    for i in range(0,len(vid),32): #len is actually no of frames.\n",
    "        X = vid[i:i+32].transpose((2,1,0,3)) #model takes 32 frames.\n",
    "        output = model.predict_on_batch(np.array([X]))\n",
    "        if abnor==3:\n",
    "            break\n",
    "        if(len(output)>0): #code doesnot break\n",
    "            str1=labels1[np.argmax(output)] #on which location of labels is the max probablity of o/p\n",
    "            if str1=='vandalism' or str1 == 'fighting' or str1=='shooting' or str1=='hockeyfight':\n",
    "                abnor=abnor+1\n",
    "            else:\n",
    "                abnor=0\n",
    "    \n",
    "    vid=[]\n",
    "    if abnor==3:\n",
    "         prediction.append('abnormal')\n",
    "    else:\n",
    "        prediction.append('normal')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f7d2c5-6ba4-4145-b2ff-2594ef982e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction) #prediction array has labels we got during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bc2501-b25c-49a5-a788-1be31177c0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(orignal, prediction)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9686280-7e02-440d-b05d-076891810bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
