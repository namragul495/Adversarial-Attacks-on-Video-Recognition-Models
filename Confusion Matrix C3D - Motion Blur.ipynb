{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5133d9ec-1b81-4589-b19f-f26effc165c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "orignal =[] #Blank array. But later on add normal and abnormal to it. original has all the labels we got during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5dc95e3-1d01-4802-aae9-67cd1d5c3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all test videos\n",
    "test=[] #It contains all labels (0 and 1). Length is 85 \n",
    "test_list2=[]\n",
    "f= 'sample_images_RA'\n",
    "Test_videos =[]  #This array contains path of all videos.Length is 85\n",
    "test_list = open('Labels/test.txt','r') # path and labels info \n",
    "for line in test_list:\n",
    "    name = line.split(\" \")[0]  \n",
    "    test_list2.append(line)\n",
    "    x=line.split(\" \")[-1]\n",
    "    test.append(x[0])\n",
    "    Test_videos.append(f+\"/\"+name) #Full path of all videos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d979bd6-a028-446f-8064-38311c43203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test: \n",
    "    if i=='0':\n",
    "        orignal.append('normal')\n",
    "    else:\n",
    "        orignal.append('abnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91d574e-85c1-4c8c-a278-8f62d415aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load pre-trained model, trained on 5 classes \n",
    "#model = tf.keras.models.load_model('Trained models/model_c3d.h5',compile=False)\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "#To load pre-trained weeights,\n",
    "model = tf.keras.models.load_model('Trained Models/weights_model_C3D.hdf5',compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8041b922-4f68-4679-b123-558095e05419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Five class labels\n",
    "labels1 = {0: 'fighting', 1: 'vandalism',2: '0normal',3: 'shooting',4: 'hockeyfight'}\n",
    "prediction = [] #Labels you get after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "302eb5ec-128c-4409-9b83-5669f049319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_motion_blur(frame, kernel_size=5, orientation='horizontal'):\n",
    "    kernel = np.zeros((kernel_size, kernel_size))\n",
    "    \n",
    "    if orientation == 'horizontal':\n",
    "        # Horizontal motion blur (default)\n",
    "        kernel[int((kernel_size - 1) / 2), :] = np.ones(kernel_size)\n",
    "    elif orientation == 'vertical':\n",
    "        # Vertical motion blur\n",
    "        kernel[:, int((kernel_size - 1) / 2)] = np.ones(kernel_size)\n",
    "    elif orientation == 'diagonal':\n",
    "        # 45-degree diagonal motion blur\n",
    "        for i in range(kernel_size):\n",
    "            kernel[i, i] = 1\n",
    "        kernel = kernel / kernel_size\n",
    "    elif orientation == 'diagonal_135':\n",
    "        # 135-degree diagonal motion blur\n",
    "        for i in range(kernel_size):\n",
    "            kernel[i, -(i + 1)] = 1\n",
    "        kernel = kernel / kernel_size\n",
    "    elif orientation == 'cross':\n",
    "        # Cross motion blur (horizontal and vertical)\n",
    "        kernel[int((kernel_size - 1) / 2), :] = np.ones(kernel_size)\n",
    "        kernel[:, int((kernel_size - 1) / 2)] = np.ones(kernel_size)\n",
    "        kernel = kernel / kernel_size\n",
    "    else:\n",
    "        raise ValueError(\"Invalid orientation. Use 'horizontal', 'vertical', 'diagonal', 'diagonal_135', or 'cross'.\")\n",
    "\n",
    "    blurred_frame = cv2.filter2D(frame, -1, kernel)\n",
    "    return blurred_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b39e831-8222-452f-a139-8477737c91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(frames, frame_rate=5):\n",
    "    \"\"\"\n",
    "    Play a sequence of frames as a video.\n",
    "\n",
    "    Parameters:\n",
    "    - frames: List of frames (numpy arrays representing images).\n",
    "    - frame_rate: Frames per second (default is 25).\n",
    "    \"\"\"\n",
    "    if not frames:\n",
    "        print(\"No frames to play.\")\n",
    "        return\n",
    "\n",
    "    # Get the height and width from the first frame\n",
    "    height, width, _ = frames[0].shape\n",
    "    size = (width, height)\n",
    "\n",
    "    # Create a VideoWriter object to save the video\n",
    "    video_writer = cv2.VideoWriter('output_video.avi', cv2.VideoWriter_fourcc(*'DIVX'), frame_rate, size)\n",
    "\n",
    "    # Display each frame and write it to the video file\n",
    "    for frame in frames:\n",
    "        cv2.imshow('Video Player', frame)\n",
    "        video_writer.write(frame)\n",
    "\n",
    "        # Break the loop if the 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the VideoWriter and close the OpenCV window\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122c2f74-d959-4813-99a8-25ebaf83ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_videos =[]\n",
    "\n",
    "#Code for Confusion Matrix\n",
    "for video in Test_videos:\n",
    "    vid = [] #reads frame of videos\n",
    "    #nor=0  #no value of nor. initialize nor with 0\n",
    "    abnor=0   #no value of abnor. initialize abnor 0\n",
    "    path=video\n",
    "    images = os.listdir(path) #Images name actually store name of all frames\n",
    "    for img in images: #read the length and width of all images.\n",
    "        img_path=path +\"/\"+img #path +img name print. path of 1 frame\n",
    "        img2 = cv2.imread(img_path) #img2 has a 2D array of integer form containing length and width of videos\n",
    "        img2 = add_motion_blur(img2, kernel_size=30, orientation='cross')\n",
    "        img2= cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "        vid.append(cv2.resize(img2, (1024,1024))) \n",
    "    all_videos.append(vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab20924-7c89-467c-90ae-51db9759d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_video(all_videos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9686280-7e02-440d-b05d-076891810bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
