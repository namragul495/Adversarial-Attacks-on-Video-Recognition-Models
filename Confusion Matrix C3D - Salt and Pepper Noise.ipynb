{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5133d9ec-1b81-4589-b19f-f26effc165c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "orignal =[] #Blank array. But later on add normal and abnormal to it. original has all the labels we got during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b5dc95e3-1d01-4802-aae9-67cd1d5c3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all test videos\n",
    "test=[] #It contains all labels (0 and 1). Length is 85 \n",
    "test_list2=[]\n",
    "f= 'sample_images_RA'\n",
    "Test_videos =[]  #This array contains path of all videos.Length is 85\n",
    "test_list = open('Labels/test.txt','r') # path and labels info \n",
    "for line in test_list:\n",
    "    name = line.split(\" \")[0]  \n",
    "    test_list2.append(line)\n",
    "    x=line.split(\" \")[-1]\n",
    "    test.append(x[0])\n",
    "    Test_videos.append(f+\"/\"+name) #Full path of all videos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8d979bd6-a028-446f-8064-38311c43203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test: \n",
    "    if i=='0':\n",
    "        orignal.append('normal')\n",
    "    else:\n",
    "        orignal.append('abnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a91d574e-85c1-4c8c-a278-8f62d415aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load pre-trained model, trained on 5 classes \n",
    "#model = tf.keras.models.load_model('Trained models/model_c3d.h5',compile=False)\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "#To load pre-trained weeights,\n",
    "model = tf.keras.models.load_model('Trained Models/weights_model_C3D.hdf5',compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8041b922-4f68-4679-b123-558095e05419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Five class labels\n",
    "labels1 = {0: 'fighting', 1: 'vandalism',2: '0normal',3: 'shooting',4: 'hockeyfight'}\n",
    "prediction = [] #Labels you get after testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "302eb5ec-128c-4409-9b83-5669f049319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_and_pepper_noise(frame, salt_prob=0.1, pepper_prob=1):\n",
    "    noisy_frame = frame.copy()\n",
    "    total_pixels = frame.size\n",
    "    num_salt = int(total_pixels * salt_prob)\n",
    "    num_pepper = int(total_pixels * pepper_prob)\n",
    "\n",
    "    # Add Salt noise\n",
    "    coords = [np.random.randint(0, i - 1, num_salt) for i in frame.shape]\n",
    "    noisy_frame[coords[0], coords[1], :] = 255\n",
    "\n",
    "    # Add Pepper noise\n",
    "    coords = [np.random.randint(0, i - 1, num_pepper) for i in frame.shape]\n",
    "    noisy_frame[coords[0], coords[1], :] = 0\n",
    "\n",
    "    return noisy_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "122c2f74-d959-4813-99a8-25ebaf83ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for Confusion Matrix\n",
    "for video in Test_videos:\n",
    "    vid = [] #reads frame of videos\n",
    "    #nor=0  #no value of nor. initialize nor with 0\n",
    "    abnor=0   #no value of abnor. initialize abnor 0\n",
    "    path=video\n",
    "    images = os.listdir(path) #Images name actually store name of all frames\n",
    "    for img in images: #read the length and width of all images.\n",
    "        img_path=path +\"/\"+img #path +img name print. path of 1 frame\n",
    "        img2 = cv2.imread(img_path) #img2 has a 2D array of integer form containing length and width of videos\n",
    "        img2 = add_salt_and_pepper_noise(img2, salt_prob=0.1, pepper_prob=1)\n",
    "        img2= cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "        vid.append(cv2.resize(img2, (112, 112))) \n",
    "    vid = np.array(vid, dtype=np.float32) #model accepts float32 type of array from training code. (no of frames, length, width)\n",
    "    for i in range(0,len(vid),32): #len is actually no of frames.\n",
    "        X = vid[i:i+32].transpose((2,1,0,3)) #model takes 32 frames.\n",
    "        output = model.predict_on_batch(np.array([X]))\n",
    "        if abnor==3:\n",
    "            break\n",
    "        if(len(output)>0): #code doesnot break\n",
    "            str1=labels1[np.argmax(output)] #on which location of labels is the max probablity of o/p\n",
    "            if str1=='vandalism' or str1 == 'fighting' or str1=='shooting' or str1=='hockeyfight':\n",
    "                abnor=abnor+1\n",
    "            else:\n",
    "                abnor=0\n",
    "    \n",
    "    vid=[]\n",
    "    if abnor==3:\n",
    "         prediction.append('abnormal')\n",
    "    else:\n",
    "        prediction.append('normal')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "76f7d2c5-6ba4-4145-b2ff-2594ef982e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction) #prediction array has labels we got during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "90bc2501-b25c-49a5-a788-1be31177c0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(orignal, prediction)\n",
    "sns.heatmap(conf_mat, square=True, annot=True, cmap='Blues', fmt='d', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9686280-7e02-440d-b05d-076891810bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
